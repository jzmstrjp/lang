#!/usr/bin/env tsx

/**
 * longå•é¡Œã‚’åˆ†æã—ã€TOEICãƒªã‚¹ãƒ‹ãƒ³ã‚°å•é¡Œã«å‡ºã¦ããã†ã ãŒ
 * ç¾åœ¨ä¸è¶³ã—ã¦ã„ã‚‹å˜èªãƒ»ã‚¤ãƒ‡ã‚£ã‚ªãƒ ã‚’ææ¡ˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
 *
 * ä½¿ç”¨ä¾‹:
 *   npm run suggest:toeic-vocabulary
 */

import { prisma } from '../src/lib/prisma';
import { WORD_COUNT_RULES } from '../src/config/problem';
import OpenAI from 'openai';
import * as fs from 'fs';
import * as path from 'path';
import { words as existingWords } from '../docs/words';
import { TEXT_MODEL } from '@/const';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

type Problem = {
  id: string;
  englishSentence: string;
  englishReply: string;
  wordCount: number;
};

type TokenUsage = {
  promptTokens: number;
  completionTokens: number;
  totalTokens: number;
};

/**
 * å•é¡Œæ–‡ã‚’åˆ†æã—ã¦TOEICã«å¿…è¦ã ãŒä¸è¶³ã—ã¦ã„ã‚‹èªå½™ã‚’ææ¡ˆ
 */
async function suggestToeicVocabulary(
  problems: Problem[],
): Promise<{ vocabulary: string[]; tokenUsage: TokenUsage }> {
  console.log(`  ${problems.length}å•ã‚’åˆ†æä¸­...`);

  // å•é¡Œæ–‡ã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
  const problemTexts = problems.map((p, idx) => {
    return `${idx + 1}. å•é¡Œæ–‡: ${p.englishSentence}\n   è¿”ç­”: ${p.englishReply}`;
  });

  const prompt = `ä»¥ä¸‹ã®è‹±ä¼šè©±å•é¡Œã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚

ã“ã‚Œã‚‰ã®å•é¡Œã‚’è¦‹ã¦ã€TOEICãƒªã‚¹ãƒ‹ãƒ³ã‚°ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆPart 1-4ï¼‰ã«é »å‡ºã™ã‚‹ãŒã€ã“ã‚Œã‚‰ã®å•é¡Œç¾¤ã«ã¯ã¾ã ååˆ†ã«ã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ãªã„å˜èªãƒ»ã‚¤ãƒ‡ã‚£ã‚ªãƒ ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚

ã€ææ¡ˆã™ã¹ãèªå½™ã®æ¡ä»¶ã€‘
- TOEICãƒªã‚¹ãƒ‹ãƒ³ã‚°å•é¡Œï¼ˆã‚ªãƒ•ã‚£ã‚¹ã€ä¼šè­°ã€æ—…è¡Œã€ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ã€ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³ã€ç—…é™¢ã€éŠ€è¡Œãªã©ã®å ´é¢ï¼‰ã§é »å‡ºã™ã‚‹èªå½™
- æ—¥æœ¬ã®ä¸­å­¦2å¹´ç”Ÿãƒ¬ãƒ™ãƒ«ã‚’è¶…ãˆã‚‹ï¼ˆé«˜æ ¡ç”Ÿä»¥ä¸Šã§å­¦ã¶ï¼‰å˜èªãƒ»ã‚¤ãƒ‡ã‚£ã‚ªãƒ 
- ãƒ“ã‚¸ãƒã‚¹ã‚·ãƒ¼ãƒ³ã‚„æ—¥å¸¸ç”Ÿæ´»ã§å®Ÿç”¨æ€§ãŒé«˜ã„èªå½™
- å®Ÿéš›ã®TOEICè©¦é¨“å¯¾ç­–ã¨ã—ã¦å­¦ç¿’ä¾¡å€¤ãŒé«˜ã„ã‚‚ã®
- å®Ÿéš›ã«å‡ºç¾ã™ã‚‹å½¢ã§ææ¡ˆï¼ˆbeå‹•è©ã®å ´åˆã¯ is, are, was, were ãªã©ï¼‰
- ä»¥ä¸‹ã®å•é¡Œç¾¤ã§æ—¢ã«æ‰±ã‚ã‚Œã¦ã„ã‚‹èªå½™ã¯é¿ã‘ã‚‹ã“ã¨

ã€å•é¡Œãƒªã‚¹ãƒˆã€‘
${problemTexts.join('\n\n')}

ã€å‡ºåŠ›å½¢å¼ã€‘
TOEICãƒªã‚¹ãƒ‹ãƒ³ã‚°å¯¾ç­–ã¨ã—ã¦è¿½åŠ ã™ã¹ãå˜èªãƒ»ã‚¤ãƒ‡ã‚£ã‚ªãƒ ã‚’JSONé…åˆ—å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
30ã€œ50å€‹ç¨‹åº¦ã‚’ç›®å®‰ã«ææ¡ˆã—ã¦ãã ã•ã„ã€‚
å‡ºåŠ›ä¾‹: ["invoice", "itinerary", "reimbursement", "is eligible for", "make arrangements"]

JSONé…åˆ—ã®ã¿ã‚’å‡ºåŠ›ã—ã€èª¬æ˜æ–‡ã¯ä¸è¦ã§ã™ã€‚`;

  try {
    const response = await openai.chat.completions.create({
      model: TEXT_MODEL,
      messages: [
        {
          role: 'user',
          content: prompt,
        },
      ],
      temperature: 0.3, // å°‘ã—å‰µé€ æ€§ã‚’æŒãŸã›ã‚‹
    });

    const content = response.choices[0].message.content?.trim() || '[]';

    // JSONéƒ¨åˆ†ã®ã¿ã‚’æŠ½å‡º
    let jsonContent = content;
    const jsonMatch = content.match(/```json\s*([\s\S]*?)\s*```/);
    if (jsonMatch) {
      jsonContent = jsonMatch[1];
    } else {
      const arrayMatch = content.match(/\[[\s\S]*\]/);
      if (arrayMatch) {
        jsonContent = arrayMatch[0];
      }
    }

    const vocabulary = JSON.parse(jsonContent) as string[];

    // ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’å–å¾—
    const tokenUsage: TokenUsage = {
      promptTokens: response.usage?.prompt_tokens || 0,
      completionTokens: response.usage?.completion_tokens || 0,
      totalTokens: response.usage?.total_tokens || 0,
    };

    console.log(`  âœ“ ${vocabulary.length}å€‹ã®èªå½™ã‚’ææ¡ˆ`);
    console.log(
      `  ğŸ“Š ãƒˆãƒ¼ã‚¯ãƒ³: ${tokenUsage.totalTokens} (å…¥åŠ›: ${tokenUsage.promptTokens}, å‡ºåŠ›: ${tokenUsage.completionTokens})`,
    );

    return { vocabulary, tokenUsage };
  } catch (error) {
    console.error(`  âŒ ææ¡ˆã‚¨ãƒ©ãƒ¼:`, error);
    return {
      vocabulary: [],
      tokenUsage: { promptTokens: 0, completionTokens: 0, totalTokens: 0 },
    };
  }
}

/**
 * docs/words.ts ã«èªå½™é…åˆ—ã‚’ä¿å­˜ã™ã‚‹
 */
function saveWords(words: string[]): void {
  const wordsFilePath = path.join(process.cwd(), 'docs', 'words.ts');

  // é…åˆ—ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆä»˜ãï¼‰
  const formattedArray = JSON.stringify(words, null, 2);

  const content = `export const words: string[] = ${formattedArray};\n`;

  fs.writeFileSync(wordsFilePath, content, 'utf-8');
  console.log(`\nğŸ’¾ docs/words.ts ã«ä¿å­˜ã—ã¾ã—ãŸï¼ˆ${words.length}å€‹ã®èªå½™ï¼‰`);
}

async function main() {
  try {
    console.log('ğŸ¯ TOEICãƒªã‚¹ãƒ‹ãƒ³ã‚°å¯¾ç­–èªå½™ææ¡ˆãƒ„ãƒ¼ãƒ«\n');

    const longRule = WORD_COUNT_RULES.long;
    console.log(`ğŸ“ longå•é¡Œã®å®šç¾©: ${longRule.min}ã€œ${longRule.max}èª\n`);

    // longå•é¡Œã‚’å…¨ã¦å–å¾—
    const longProblems = await prisma.problem.findMany({
      where: {
        wordCount: {
          gte: longRule.min,
          lte: longRule.max,
        },
      },
      select: {
        id: true,
        englishSentence: true,
        englishReply: true,
        wordCount: true,
      },
    });

    console.log(`ğŸ“Š ${longProblems.length}å€‹ã®longå•é¡Œã‚’å–å¾—ã—ã¾ã—ãŸ\n`);

    if (longProblems.length === 0) {
      console.log('âš ï¸  longå•é¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ');
      return;
    }

    // ãƒãƒƒãƒå‡¦ç†ï¼ˆ50å•ãšã¤ï¼‰
    const batchSize = 50;
    const batches: Problem[][] = [];

    for (let i = 0; i < longProblems.length; i += batchSize) {
      batches.push(longProblems.slice(i, i + batchSize));
    }

    console.log(`ğŸ“¦ ãƒãƒƒãƒã‚µã‚¤ã‚º: ${batchSize}å•/ãƒãƒƒãƒ`);
    console.log(`ğŸ¤– OpenAI APIã§TOEICèªå½™ã‚’ææ¡ˆä¸­... (${batches.length}ãƒãƒƒãƒ)\n`);

    // Setã§é‡è¤‡ã‚’è‡ªå‹•æ’é™¤
    const allVocabulary = new Set<string>();
    const totalTokenUsage: TokenUsage = {
      promptTokens: 0,
      completionTokens: 0,
      totalTokens: 0,
    };

    for (let i = 0; i < batches.length; i++) {
      const batch = batches[i];
      console.log(`ğŸ“¦ ãƒãƒƒãƒ ${i + 1}/${batches.length}:`);

      const result = await suggestToeicVocabulary(batch);
      result.vocabulary.forEach((word) => allVocabulary.add(word));

      // ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’ç´¯ç©
      totalTokenUsage.promptTokens += result.tokenUsage.promptTokens;
      totalTokenUsage.completionTokens += result.tokenUsage.completionTokens;
      totalTokenUsage.totalTokens += result.tokenUsage.totalTokens;

      // API rate limitã‚’è€ƒæ…®ã—ã¦å°‘ã—å¾…æ©Ÿ
      if (i < batches.length - 1) {
        await new Promise((resolve) => setTimeout(resolve, 1000));
      }
    }

    // longå•é¡Œã«æ—¢ã«ç™»å ´ã—ã¦ã„ã‚‹èªå½™ã‚’é™¤å¤–
    console.log('\nğŸ” longå•é¡Œã«æ—¢ã«ç™»å ´ã—ã¦ã„ã‚‹èªå½™ã‚’ãƒã‚§ãƒƒã‚¯ä¸­...\n');

    // longã®å…¨ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆï¼ˆæ¤œç´¢ç”¨ï¼‰
    const longTexts = longProblems
      .map((p) => `${p.englishSentence} ${p.englishReply}`)
      .join(' ')
      .toLowerCase();

    // longã«ç™»å ´ã—ã¦ã„ãªã„èªå½™ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    const notInLong = Array.from(allVocabulary).filter((vocab) => {
      const pattern = vocab.toLowerCase();
      return !longTexts.includes(pattern);
    });

    console.log(`ğŸ“Š ææ¡ˆã•ã‚ŒãŸèªå½™: ${allVocabulary.size}å€‹`);
    console.log(`âŒ longå•é¡Œã«æ—¢ã«å­˜åœ¨: ${allVocabulary.size - notInLong.length}å€‹`);
    console.log(`âœ… æœ¬å½“ã«ä¸è¶³ã—ã¦ã„ã‚‹èªå½™: ${notInLong.length}å€‹\n`);

    // çµæœã‚’ã‚½ãƒ¼ãƒˆ
    const sortedVocabulary = notInLong.sort((a, b) => {
      // å˜èªæ•°ã§ã‚½ãƒ¼ãƒˆï¼ˆå˜èªâ†’ãƒ•ãƒ¬ãƒ¼ã‚ºã®é †ï¼‰
      const aWordCount = a.split(' ').length;
      const bWordCount = b.split(' ').length;
      if (aWordCount !== bWordCount) {
        return aWordCount - bWordCount;
      }
      // ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆé †
      return a.localeCompare(b);
    });

    // ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã®çµ±è¨ˆ
    console.log('ğŸ“Š ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡çµ±è¨ˆ:');
    console.log(`  å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³: ${totalTokenUsage.promptTokens.toLocaleString()}`);
    console.log(`  å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³: ${totalTokenUsage.completionTokens.toLocaleString()}`);
    console.log(`  åˆè¨ˆãƒˆãƒ¼ã‚¯ãƒ³: ${totalTokenUsage.totalTokens.toLocaleString()}`);

    const inputCost = (totalTokenUsage.promptTokens / 1_000_000) * 1.75;
    const outputCost = (totalTokenUsage.completionTokens / 1_000_000) * 14.0;
    const totalCost = inputCost + outputCost;

    console.log(
      `  æ¨å®šã‚³ã‚¹ãƒˆ (gpt-5.2): $${totalCost.toFixed(4)} (ç´„${Math.ceil(totalCost * 150)}å††)\n`,
    );

    // çµæœã‚’å‡ºåŠ›
    console.log('ğŸ“‹ æœ¬å½“ã«ä¸è¶³ã—ã¦ã„ã‚‹TOEICèªå½™ä¸€è¦§:\n');
    console.log(JSON.stringify(sortedVocabulary, null, 2));

    // ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«é›†è¨ˆ
    const singleWords = sortedVocabulary.filter((v) => !v.includes(' '));
    const phrases = sortedVocabulary.filter((v) => v.includes(' '));

    console.log('\nğŸ“Š ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ:');
    console.log(`  å˜èª: ${singleWords.length}å€‹`);
    console.log(`  ã‚¤ãƒ‡ã‚£ã‚ªãƒ : ${phrases.length}å€‹`);

    // docs/words.ts ã«ä¿å­˜
    console.log('\nğŸ’¾ docs/words.ts ã¸ã®ä¿å­˜ã‚’æº–å‚™ä¸­...');
    console.log(`ğŸ“‚ æ—¢å­˜ã®èªå½™æ•°: ${existingWords.length}å€‹`);

    // æ—¢å­˜ã®èªå½™ã¨æ–°è¦ã®èªå½™ã‚’çµ±åˆï¼ˆé‡è¤‡æ’é™¤ã€æœ«å°¾ã«è¿½åŠ ï¼‰
    const existingWordsSet = new Set(existingWords);
    const newWords = sortedVocabulary.filter((word) => !existingWordsSet.has(word));
    const allWords = [...existingWords, ...newWords];

    const newWordsCount = allWords.length - existingWords.length;
    console.log(`â• æ–°è¦è¿½åŠ : ${newWordsCount}å€‹`);
    console.log(`ğŸ“Š åˆè¨ˆ: ${allWords.length}å€‹`);

    // ä¿å­˜
    saveWords(allWords);
  } catch (error) {
    console.error('âŒ å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:', error);
    process.exitCode = 1;
  } finally {
    await prisma.$disconnect();
  }
}

if (require.main === module) {
  main()
    .then(() => {
      process.exit(0);
    })
    .catch((error) => {
      console.error('Fatal error:', error);
      process.exit(1);
    });
}

export { main };
